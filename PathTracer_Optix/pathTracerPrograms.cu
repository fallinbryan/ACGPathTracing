/**
 * This file is part of a project utilizing the NVIDIA OptiX ray tracing engine. It contains a collection of functions and structures
 * essential for the implementation of a path tracer. The documentations (docstrings) for functions and structures within this file
 * have been generated by ChatGPT-4, an AI developed by OpenAI, to provide clear, concise, and detailed explanations of the code's
 * functionality and its interaction with the OptiX framework. These docstrings aim to enhance code readability and maintainability,
 * offering insights into the implementation details and usage examples. It's important to note that while the docstrings are crafted
 * to accurately describe the code and its purpose within the context of OptiX-based ray tracing, they should be considered as
 * supplementary explanations and may not cover all nuances of the OptiX API or the specific application logic.
 */




#include <optix.h>


#include "pathTracer.h"
#include "random.h"

#include <sutil/vec_math.h>
#include <cuda/helpers.h>


extern "C" {
  __constant__ PathTraceParams params;
}

/**
 * @brief Constructs an orthonormal basis given a surface normal. Originally named `Onb` in the NVIDIA OptiX Toolkit.
 *
 * This structure is used to generate an orthonormal basis (tangent, binormal, normal) for a given surface normal. It is crucial
 * for shading and lighting calculations in ray tracing. By ensuring orthogonality and avoiding degenerate vectors, it aids in
 * converting vectors between coordinate systems and generating random sample directions on a hemisphere.
 *
 * The implementation is taken directly from the NVIDIA OptiX ray tracing toolkit, with the only modification being the change
 * of the structure name from `Onb` to `OrthonormalBasis` for clarity. This modification enhances readability without altering
 * the original logic or functionality provided by the toolkit.
 *
 * Usage:
 * Given a surface normal `N`, an `OrthonormalBasis` object is constructed. The tangent and binormal vectors are then
 * computed to be orthogonal to `N` and each other, which is essential for transforming directions between the local surface
 * coordinate system and the world coordinate system.
 *
 * Example:
 * ```
 * float3 N = make_float3(0.0f, 1.0f, 0.0f); // Surface normal
 * OrthonormalBasis onb(N);
 * // Use `onb` to transform vectors between world and local space
 * ```
 *
 * Note: The original `Onb` code is from the NVIDIA OptiX Toolkit. The renaming to `OrthonormalBasis` is the sole modification
 * made to enhance code clarity.
 */
struct OrthonormalBasis
{
  __forceinline__ __device__ OrthonormalBasis(const float3& normal)
  {
    m_normal = normal;

    if (fabs(m_normal.x) > fabs(m_normal.z))
    {
      m_binormal.x = -m_normal.y;
      m_binormal.y = m_normal.x;
      m_binormal.z = 0;
    }
    else
    {
      m_binormal.x = 0;
      m_binormal.y = -m_normal.z;
      m_binormal.z = m_normal.y;
    }

    m_binormal = normalize(m_binormal);
    m_tangent = cross(m_binormal, m_normal);
  }

  __forceinline__ __device__ void inverse_transform(float3& p) const
  {
    p = p.x * m_tangent + p.y * m_binormal + p.z * m_normal;
  }

  float3 m_tangent;
  float3 m_binormal;
  float3 m_normal;
};


/**
 * @brief Loads the radiance payload data for a ray that has hit a surface, directly from the NVIDIA OptiX Toolkit.
 *
 * This function retrieves radiance payload data encoded within the ray payload. It's used in closest hit programs
 * to access the current state of the radiance payload, which includes attributes like attenuation (color attenuation
 * through the path), random seed (for stochastic processes), recursion depth, and the reason a path tracing operation
 * is considered complete (e.g., ray miss, maximum depth reached). This mechanism allows for efficient communication
 * between the ray generation, hit, and miss programs within the OptiX framework.
 *
 * The function utilizes OptiX's API to extract payload values that were previously set by the ray generation program
 * or during payload setup. The values are interpreted according to the custom `RadiancePayloadRayData` structure,
 * facilitating structured access to the payload data within closest hit shaders.
 *
 * Usage:
 * This function is typically called at the beginning of a closest hit shader to initialize a local instance of
 * `RadiancePayloadRayData` with the current state of the ray's traversal and shading calculations.
 *
 * Example:
 * ```
 * // Inside a closest hit shader:
 * RadiancePayloadRayData prd = loadClosesthitRadiancePRD();
 * // Use `prd` to continue shading calculations...
 * ```
 *
 * Note: This function is provided as part of the NVIDIA OptiX Toolkit and is used with slight modification, adding the doneReason to the payload for debugging.
 */
static __forceinline__ __device__ RadiancePayloadRayData loadClosesthitRadiancePRD()
{
  RadiancePayloadRayData prd = {};

  prd.attenuation.x = __uint_as_float(optixGetPayload_0());
  prd.attenuation.y = __uint_as_float(optixGetPayload_1());
  prd.attenuation.z = __uint_as_float(optixGetPayload_2());
  prd.randomSeed = optixGetPayload_3();
  prd.depth = optixGetPayload_4();
  prd.doneReason = (DoneReason)(optixGetPayload_18());
  return prd;
}

static __forceinline__ __device__ VolumePayLoadRayData loadClosesthitVolumePRD()
{
  VolumePayLoadRayData prd = {};

  prd.attenuation.x = __uint_as_float(optixGetPayload_0());
  prd.attenuation.y = __uint_as_float(optixGetPayload_1());
  prd.attenuation.z = __uint_as_float(optixGetPayload_2());
  prd.randomSeed = optixGetPayload_3();
  prd.step = optixGetPayload_4();
  prd.doneReason = (DoneReason)(optixGetPayload_18());
  prd.tMax = __uint_as_float(optixGetPayload_19());
  return prd;
}

/**
 * @brief Initializes and returns an empty radiance payload data structure for rays that miss geometry, directly from the NVIDIA OptiX Toolkit.
 *
 * This function is called within miss programs to initialize a `RadiancePayloadRayData` structure with default values.
 * When a ray does not intersect any geometry in the scene, the miss program is invoked, and this function provides a
 * clean slate `RadiancePayloadRayData` instance. This instance can then be used to set default or environmental values
 * for the radiance payload, such as background illumination or sky models, which are applied to rays that do not hit any objects.
 *
 * The function essentially creates a new, zero-initialized instance of `RadiancePayloadRayData`, ensuring that all fields
 * start with default values. This is crucial for correctly handling rays that miss all geometry, ensuring they contribute
 * appropriately to the scene's lighting and shading.
 *
 * Usage:
 * Typically invoked at the start of a miss shader to obtain a fresh radiance payload data structure, which is then
 * potentially modified to represent environmental contributions to the ray's radiance.
 *
 * Example:
 * ```
 * // Inside a miss shader:
 * RadiancePayloadRayData prd = loadMissRadiancePRD();
 * // Set environmental lighting values...
 * ```
 *
 * Note: This function is provided as part of the NVIDIA OptiX Toolkit and is used without modification.
 */
static __forceinline__ __device__ RadiancePayloadRayData loadMissRadiancePRD()
{
  RadiancePayloadRayData prd = {};
  return prd;
}

static __forceinline__ __device__ VolumePayLoadRayData loadMissVolumePRD()
{
  VolumePayLoadRayData prd = {};
  return prd;
}


/**
 * @brief Stores the state of `RadiancePayloadRayData` into the OptiX payload slots after closest hit calculations, directly from the NVIDIA OptiX Toolkit.
 *
 * This function encapsulates the process of encoding the radiance payload data back into the ray payload after performing
 * closest hit shading calculations. It is crucial for passing updated shading information (like attenuation, radiance, and
 * auxiliary data such as ray origin and direction for subsequent bounces) back to the OptiX framework for further processing
 * or for use in subsequent ray generations. Each component of the `RadiancePayloadRayData` structure is carefully encoded
 * into specific payload slots using OptiX API calls.
 *
 * The use of `__float_as_uint` for encoding floating-point values into unsigned integers is a standard technique for preserving
 * the bit representation of float values when storing them in the integer-typed payload slots provided by OptiX.
 *
 * Usage:
 * This function is invoked within closest hit shaders to update the ray payload with the results of shading computations,
 * effectively communicating these results back to the OptiX framework or to other shaders (like miss or ray generation shaders)
 * that might utilize this updated payload data.
 *
 * Example:
 * ```
 * // Inside a closest hit shader, after performing shading calculations:
 * storeClosesthitRadiancePRD(prd);
 * ```
 *
 * Note: This function is provided as part of the NVIDIA OptiX Toolkit and is used without modification.
 */
static __forceinline__ __device__ void storeClosesthitRadiancePRD(RadiancePayloadRayData prd)
{
  optixSetPayload_0(__float_as_uint(prd.attenuation.x));
  optixSetPayload_1(__float_as_uint(prd.attenuation.y));
  optixSetPayload_2(__float_as_uint(prd.attenuation.z));

  optixSetPayload_3(prd.randomSeed);
  optixSetPayload_4(prd.depth);

  optixSetPayload_5(__float_as_uint(prd.emissionColor.x));
  optixSetPayload_6(__float_as_uint(prd.emissionColor.y));
  optixSetPayload_7(__float_as_uint(prd.emissionColor.z));

  optixSetPayload_8(__float_as_uint(prd.radiance.x));
  optixSetPayload_9(__float_as_uint(prd.radiance.y));
  optixSetPayload_10(__float_as_uint(prd.radiance.z));

  optixSetPayload_11(__float_as_uint(prd.origin.x));
  optixSetPayload_12(__float_as_uint(prd.origin.y));
  optixSetPayload_13(__float_as_uint(prd.origin.z));

  optixSetPayload_14(__float_as_uint(prd.direction.x));
  optixSetPayload_15(__float_as_uint(prd.direction.y));
  optixSetPayload_16(__float_as_uint(prd.direction.z));

  optixSetPayload_17(prd.done);
  optixSetPayload_18(prd.doneReason);

}

/**
 * @brief Stores the updated radiance payload data for a miss shader into the OptiX payload slots, directly from the NVIDIA OptiX Toolkit.
 *
 * This function is utilized within miss shaders to encode the results of environmental lighting calculations (or lack thereof)
 * back into the ray payload. It specifically updates payload slots with information related to emission color, overall radiance,
 * and termination status of the ray. Such a mechanism is pivotal for integrating environmental contributions into the global
 * illumination calculation, especially for rays that do not intersect with any scene geometry.
 *
 * Encoding of floating-point values into the payload slots is achieved through the `__float_as_uint` function, ensuring the
 * precise bit representation of each float value is maintained. This is essential for the accurate transmission of shading data
 * within the GPU's memory constraints and the OptiX framework's architecture.
 *
 * Usage:
 * Called at the end of a miss shader to relay environmental lighting data and ray termination information back to the OptiX
 * engine or to subsequent shaders that may depend on this updated payload data.
 *
 * Example:
 * ```
 * // After calculating environmental contributions in a miss shader:
 * storeMissRadiancePRD(prd);
 * ```
 *
 * Note: This function is part of the unmodified utilities provided by the NVIDIA OptiX Toolkit, ensuring consistency and
 * reliability in handling ray payload data across different stages of the ray tracing pipeline.
 */
static __forceinline__ __device__ void storeMissRadiancePRD(RadiancePayloadRayData prd)
{
  optixSetPayload_5(__float_as_uint(prd.emissionColor.x));
  optixSetPayload_6(__float_as_uint(prd.emissionColor.y));
  optixSetPayload_7(__float_as_uint(prd.emissionColor.z));

  optixSetPayload_8(__float_as_uint(prd.radiance.x));
  optixSetPayload_9(__float_as_uint(prd.radiance.y));
  optixSetPayload_10(__float_as_uint(prd.radiance.z));

  optixSetPayload_17(prd.done);
  optixSetPayload_18(prd.doneReason);
}


/**
 * @brief Safely divides two floating point numbers.
 *
 * This function performs a division operation between two floating point numbers.
 * It checks if the denominator is zero to avoid division by zero errors.
 * If the denominator is zero, the function returns zero. Otherwise, it returns the result of the division.
 *
 * @param a The numerator of the division operation.
 * @param b The denominator of the division operation.
 * @return The result of the division if the denominator is not zero, otherwise zero.
 */
static __forceinline__ __device__ float safeDivide(float a, float b)
{
  return b == 0.0f ? 0.0f : a / b;
}

/**
 * @brief Safely divides a float3 vector by a floating point number.
 *
 * This function performs a division operation between a float3 vector and a floating point number.
 * It checks if the denominator is zero to avoid division by zero errors.
 * If the denominator is zero, the function returns a zero vector. Otherwise, it returns the result of the division.
 *
 * @param a The float3 vector to be divided.
 * @param b The denominator of the division operation.
 * @return The result of the division if the denominator is not zero, otherwise a zero vector.
 */
static __forceinline__ __device__ float3 safeDivide(float3 a, float b) {
  return make_float3(safeDivide(a.x, b), safeDivide(a.y, b), safeDivide(a.z, b));

}


/**
 * @brief Cosine-weighted importance sampling for a hemisphere.
 *
 * This function uses Monte Carlo integration to sample a direction within a hemisphere based on two random input values (u1 and u2).
 * The generated direction is used in path tracing algorithms for light transport simulations.
 * The direction is sampled based on the cosine of the angle between the direction and the normal of the hemisphere.
 * This is an importance sampling method that generates directions that are more likely to be chosen based on the cosine of the angle.
 * This helps to reduce the variance and produce a more accurate image.
 *
 * However, this function has been observed to produce unexpected rendering results. The azimuth distribution is non-uniform, which leads to extreme artifacts in the rendered image.
 *
 * @param u1 A random float value between 0 and 1.
 * @param u2 A random float value between 0 and 1.
 * @param p The output sampled direction within the hemisphere.
 */
static __forceinline__ __device__ void jankun_cosine_sample_hemisphere(const float eta1, const float eta2, float3& p)
{
  // Transform eta1 and eta2 from [0, 1) to [-1, 1)
  float eta1_prime = 2.0f * eta1 - 1.0f;
  float eta2_prime = 2.0f * eta2 - 1.0f;

  float r, phi;

  // Determine r and phi using the safeDivide function to avoid division by zero
  if (eta1 > eta2) {
    r = eta1_prime;
    phi = M_PIf / 4.0f * safeDivide(eta2_prime, eta1_prime);
  }
  else {
    r = eta2_prime;
    phi = M_PIf / 4.0f * safeDivide(eta1_prime, eta2_prime);
  }

  // Convert polar to Cartesian coordinates
  p.x = r * cosf(phi);
  p.y = r * sinf(phi);

  // Adjust z based on the exact mathematics from the lecture
  p.z = 1.0f - p.x * p.x - p.y * p.y; 
}

/**
 * @brief Cosine-weighted importance sampling for a hemisphere.
 *
 * This function uses Monte Carlo integration to sample a direction within a hemisphere based on two random input values (u1 and u2).
 * The generated direction is used in path tracing algorithms for light transport simulations.
 * The direction is sampled based on the cosine of the angle between the direction and the normal of the hemisphere.
 * This is an importance sampling method that generates directions that are more likely to be chosen based on the cosine of the angle.
 * This helps to reduce the variance and produce a more accurate image.
 *
 * @param eta1 A random float value between 0 and 1.
 * @param eta2 A random float value between 0 and 1.
 * @param p The output sampled direction within the hemisphere.
 */
static __forceinline__ __device__ void cosine_sample_hemisphere(const float eta1, const float eta2, float3& p)
{

  //The monte carlo probability that this direction was sampled is cos(theta) / PI
  //The reflectance of the lambertian surface is R / PI

  const float theta = acosf(sqrtf(eta1));
  const float phi = 2.0f * M_PIf * eta2;
  p.x = sinf(theta) * cosf(phi);
  p.y = sinf(theta) * sinf(phi);
  p.z = cosf(theta);

}

/**
 * @brief Uniformly samples a direction within a hemisphere.
 *
 * This function uses Monte Carlo integration to uniformly sample a direction within a hemisphere.
 * It generates a random direction within a hemisphere based on two random input values (u1 and u2).
 * The generated direction is used in path tracing algorithms for light transport simulations.
 * The direction is sampled uniformly, meaning each direction within the hemisphere has an equal chance of being chosen.
 * This function is NOT an importance sampling method.
 *
 * @param u1 A random float value between 0 and 1.
 * @param u2 A random float value between 0 and 1.
 * @param wi The output sampled direction within the hemisphere.
 */
static __forceinline__ __device__ void uniform_sample_hemisphere(const float u1, const float u2, float3& wi) 
{
  
  //The monte carlo probability that this direction was sampled is 2 / PI
  //The reflectance of the lambertian surface is R / PI

  const float theta = acosf(u1);
  const float phi = 2.0f * M_PIf * u2;
  wi.x =  cosf(phi) * sqrtf(1-u1*u1);
  wi.y =  sinf(phi) * sqrtf(1-u1*u1);
  wi.z =  u1;

}


/**
 * @brief Converts a DoneReason enum value to a string.
 *
 * This function takes a DoneReason enum value and returns a string representation of it.
 * The DoneReason enum represents the reason why the path tracing for a ray is done.
 * The possible reasons are: MISS (the ray missed all geometry), MAX_DEPTH (the ray reached the maximum recursion depth),
 * RUSSIAN_ROULETTE (the ray was terminated due to Russian roulette), and NOT_DONE (the ray is not done yet).
 *
 * @param reason The DoneReason enum value to be converted to a string.
 * @return A string representation of the DoneReason enum value.
 */
static __forceinline__ __device__ const char* doneReasonToString(DoneReason reason)
{
  switch (reason)
  {
  case DoneReason::MISS:
    return "MISS";
  case DoneReason::MAX_DEPTH:
    return "MAX_DEPTH";
  case DoneReason::RUSSIAN_ROULETTE:
    return "RUSSIAN_ROULETTE";
  case DoneReason::NOT_DONE:
    return "NOT_DONE";
  default:
    return "UNKNOWN";
  }
}


/**
 * @brief Checks for "void pixels," where a GPU's silent contemplation on division by zero leaves behind a colorless void.
 *
 * This function handles those special moments, marking the presence of what we've affectionately dubbed "void pixels." These are the enigmatic outcomes of calculations that tread into the realm where traditional mathematics would rather not, leaving us with pixels devoid of all RGB valuesï¿½quiet testimonies to a computational anomaly.
 *
 * A void pixel is defined by its RGB components all resting peacefully at 0.0f. While the term itself might not be found in standard graphics programming lexicons, it's a concise encapsulation of those peculiar instances we occasionally encounter in the digital wilderness.
 *
 * @param pixel A float3 structure representing the RGB values of the pixel: `x` for red, `y` for green, and `z` for blue. Each channel's value as a float determines if the pixel belongs to the realm of the void.
 *
 * @return bool True indicates the pixel is indeed void, carrying no color; false suggests it bears the vibrant mark of existence.
 */
static __forceinline__ __device__ bool isThisAVoidPixel(const float3& pixel)
{
  return pixel.x == 0.0f && pixel.y == 0.0f && pixel.z == 0.0f;
}




/**
 * @brief Samples a vector according to the GGX (Trowbridge-Reitz) normal distribution function for microfacet models.
 *
 * This function generates a sample vector on the hemisphere around a normal vector `N`, distributed according to the GGX
 * microfacet distribution. The GGX distribution is used in physically based rendering to model the scattering of light
 * from surfaces with microfacet orientation distribution. It is particularly useful for simulating the appearance of rough
 * surfaces. The sampling is performed in the local space defined by `N` and then transformed to the world space.
 *
 * The function takes two uniform random variables `u1` and `u2` to produce a stochastically sampled direction that mimics
 * the distribution of normals according to the GGX model. The `roughness` parameter controls the spread of the distribution,
 * with higher values resulting in more spread-out highlights and a rougher surface appearance.
 *
 * @param u1 A uniform random variable in the range [0,1], used to stochastically sample the azimuthal angle.
 * @param u2 A uniform random variable in the range [0,1], used to stochastically sample the polar angle.
 * @param roughness The roughness parameter of the surface, affecting the spread of the GGX distribution. This is clamped
 * between 0.001 and 1.0 to avoid division by zero and ensure numerical stability.
 * @param N The surface normal at the point of interest, used to define the hemisphere of sampling.
 *
 * @return float3 The sampled direction vector in world space, normalized. This vector represents a possible microfacet normal
 * direction according to the GGX distribution, given the input roughness and uniform random variables.
 *
 * @note The function employs a geometric transformation to ensure that the sampled vector is distributed correctly with respect
 * to the input normal `N`, thus correctly simulating the anisotropic effects of microfacet distributions on rough surfaces.
 */
static __forceinline__ __device__ float3 sampleGGX(float u1, float u2, float roughness, const float3& N)
{
  // Convert (u1, u2) uniform random variables into GGX distribution
  clamp(roughness, 0.001f, 1.0f); // Avoid division by zero (roughness = 0.0f is not allowed
  float phi = 2.0f * M_PIf * u1;
  float cosTheta = sqrtf((1.0f - u2) / (1.0f + (roughness * roughness - 1.0f) * u2));
  float sinTheta = sqrtf(1.0f - cosTheta * cosTheta);

  // Create sample vector in tangent space
  float3 H;
  H.x = sinTheta * cosf(phi);
  H.y = sinTheta * sinf(phi);
  H.z = cosTheta;

  // Transform H to world space
  float3 up = fabsf(N.z) < 0.999 ? make_float3(0, 0, 1) : make_float3(1, 0, 0);
  float3 tangent = normalize(cross(up, N));
  float3 bitangent = cross(N, tangent);
  float3 sampleDir = H.x * tangent + H.y * bitangent + H.z * N;

  return normalize(sampleDir);
}

/**
 * @brief Computes the Fresnel reflectance for a conductor using the Schlick approximation. Function derived from the PBR Book.
 *
 * This function calculates the Fresnel reflectance for conducting materials based on the Schlick approximation. It is designed
 * to handle the complex interactions of light with materials that have both a complex index of refraction (`eta`) and an
 * absorption coefficient (`k`). These parameters are crucial for accurately modeling the way light reflects off surfaces,
 * especially metals, in physically based rendering. By taking into account the cosine of the angle of incidence and the
 * material's optical properties, the function provides a realistic estimation of reflectance across the RGB spectrum.
 *
 * @param cosTheta The cosine of the angle between the light direction and the surface normal.
 * @param eta The complex index of refraction of the material for each RGB component, representing the real part of the material's refractive index.
 * @param k The absorption coefficient for each RGB component, representing the imaginary part of the material's refractive index that accounts for light absorption.
 * @return float3 The reflectance for each RGB channel, providing an approximation of how much light is reflected by the material at the given angle of incidence.
 *
 * This reflectance calculation is a key component in the rendering of metallic surfaces, where accurate depiction of light interaction is essential for realism.
 */
static __forceinline__ __device__ float3 fresnelSchlickConductor(float cosTheta, float3 eta, float3 k)
{
  float3 eta2 = eta * eta;
  float3 k2 = k * k;

  float3 t1 = eta2 - k2 - make_float3(cosTheta * cosTheta);
  float3 a2plusb2 = make_float3(sqrtf(t1.x * t1.x + 4 * eta2.x * k2.x),
    sqrtf(t1.y * t1.y + 4 * eta2.y * k2.y),
    sqrtf(t1.z * t1.z + 4 * eta2.z * k2.z));

  float3 t2 = a2plusb2 + make_float3(cosTheta * cosTheta);

  float3 Rs = (t2 - 2 * eta * cosTheta + make_float3(cosTheta * cosTheta)) / (t2 + 2 * eta * cosTheta + make_float3(cosTheta * cosTheta));
  float3 Rp = Rs * (t2 - 2 * eta * cosTheta + make_float3(1)) / (t2 + 2 * eta * cosTheta + make_float3(1));

  return (Rs + Rp) * 0.5f;
}

/**
 * @brief Calculates the Fresnel reflectance for dielectric materials. Adapted from the PBR Book.
 *
 * This function computes the Fresnel reflectance at the interface between two dielectric media based on the
 * indices of refraction of the incident and transmitted media and the cosine of the incident angle. This calculation
 * is essential for accurately rendering the behavior of light as it transitions between different media, such as air
 * and water or glass, which is critical for realistic rendering of transparent and reflective surfaces in physically
 * based rendering.
 *
 * The function handles total internal reflection, where no light is transmitted across the boundary, and returns the
 * proportion of light reflected back into the incident medium. It adjusts the indices of refraction based on the
 * direction of incidence to ensure accuracy regardless of the light's entry point.
 *
 * @param cosThetaI The cosine of the angle of incidence, which is the angle between the incident light direction
 *                  and the normal to the surface at the point of interaction.
 * @param etaI The index of refraction of the incident medium.
 * @param etaT The index of refraction of the transmitted medium.
 * @return float The Fresnel reflectance, representing the fraction of incident light that is reflected by the interface.
 *
 * The calculation assumes the interface between two dielectrics is smooth, making it a cornerstone for simulations
 * involving light interaction with transparent or semi-transparent materials.
 */
static __forceinline__ __device__ float FrDielectric(float cosThetaI, float etaI, float etaT) {
  cosThetaI = clamp(cosThetaI, -1.0f, 1.0f);
  // Flip the interface orientation if the incident ray is inside the material
  bool entering = cosThetaI > 0.0f;
  if (!entering) {
    // Swap etaI and etaT for rays inside the material
    float temp = etaI;
    etaI = etaT;
    etaT = temp;
    cosThetaI = fabs(cosThetaI);
  }

  float sinThetaI = sqrtf(fmaxf(0.0f, 1.0f - cosThetaI * cosThetaI));
  float sinThetaT = etaI / etaT * sinThetaI;

  // Total internal reflection
  if (sinThetaT >= 1.0f) {
    return 1.0f; // When sinThetaT is greater or equal to 1, it indicates total internal reflection.
  }

  float cosThetaT = sqrtf(fmaxf(0.0f, 1.0f - sinThetaT * sinThetaT));

  float rParl = ((etaT * cosThetaI) - (etaI * cosThetaT)) / ((etaT * cosThetaI) + (etaI * cosThetaT));
  float rPerp = ((etaI * cosThetaI) - (etaT * cosThetaT)) / ((etaI * cosThetaI) + (etaT * cosThetaT));
  return (rParl * rParl + rPerp * rPerp) / 2.0f;
}

static __forceinline__ __device__ void ShadeDiffuse(RadiancePayloadRayData& prd, HitGroupData* rt_data, float3 hitPoint, float3 normal) {
  unsigned int seed = prd.randomSeed;
  const bool      useImportanceSampling = params.useImportanceSampling;
  const float z1 = rnd(seed);
  const float z2 = rnd(seed);
  OrthonormalBasis onb(normal);
  float3 w_in;

  if (useImportanceSampling)
  {
    cosine_sample_hemisphere(z1, z2, w_in);
    onb.inverse_transform(w_in);
  }
  else
  {
    uniform_sample_hemisphere(z1, z2, w_in);
    onb.inverse_transform(w_in);
  }

  prd.direction = w_in;
  prd.origin = hitPoint;
  prd.attenuation *= rt_data->diffuseColor;
}

static __forceinline__ __device__ void ShadeMetallic(RadiancePayloadRayData& prd, HitGroupData* rt_data, float3 hitPoint, float3 normal, float3 ray_dir)
{
  const float     metalRoughOffset = params.metallicRoughness;
  unsigned int    seed = prd.randomSeed;
  float           roughness = rt_data->roughness;
  roughness += metalRoughOffset;
  clamp(roughness, 0.001f, 1.0f);

  const float z1 = rnd(seed);
  const float z2 = rnd(seed);
  float3 microfacetNormal = sampleGGX(z1, z2, roughness, normal);
  float3 R = reflect(ray_dir, microfacetNormal);

  prd.direction = R;
  prd.origin = hitPoint + R * 1e-4f;


  float3 eta = make_float3(1.45, 0.7, 1.55); // Slightly more refraction in the blue channel
  float3 k = make_float3(3.0, 2.2, 3.5); // Higher absorption in the red and blue channels
  float cosTheta = fmaxf(dot(microfacetNormal, -ray_dir), 0.0f);
  float3 F = fresnelSchlickConductor(cosTheta, eta, k);
  float3 F0 = rt_data->diffuseColor; // The base color of the material
  float3 color = F * F0;

  prd.attenuation *= color;
}

static __forceinline__ __device__ void ShadeDielectric(RadiancePayloadRayData& prd, HitGroupData* rt_data, float3 hitPoint, float3 normal, float3 ray_dir) {  
  const float     refractRoughOffset = params.refractiveRoughness;
  unsigned int    seed = prd.randomSeed;
  const float     z1 = rnd(seed);
  const float     z2 = rnd(seed);
  float           roughness = rt_data->roughness;
  const float     IOR = rt_data->IOR;

  roughness += refractRoughOffset;
  clamp(roughness, 0.001f, 1.0f);

  float3 incidentRayDir = normalize(ray_dir);

  float3 microFacetNormal = sampleGGX(z1, z2, roughness, normal);

  float cos_theta = dot(-incidentRayDir, microFacetNormal);
  float F = FrDielectric(cos_theta, 1.0f, IOR);


  if (rnd(seed) < F) {
    prd.direction = reflect(incidentRayDir, microFacetNormal);

  }
  else {

    float3 refractedDir; // Initialized by the refract function
    bool didRefract = refract(refractedDir, incidentRayDir, microFacetNormal, IOR);
    if (didRefract) {
      prd.direction = refractedDir;
    }
    else {
      prd.direction = reflect(incidentRayDir, microFacetNormal);
    }
  }
  prd.origin = hitPoint + prd.direction * 1e-3f;
  prd.attenuation *= rt_data->diffuseColor;
}

/**
 * @brief Traces a ray through the scene and updates the payload with the radiance information.
 *
 * This function uses the OptiX API to trace a ray through the scene and gather radiance information.
 * optixTraverse is used to trace the ray and optixInvoke is used to invoke the relavant shader.
 * The relvant shader will update the payload with the radiance and attenuation information.
 *
 * @param handle The handle to the traversable object (scene) to trace the ray through.
 * @param ray_origin The origin of the ray.
 * @param ray_direction The direction of the ray.
 * @param tmin The minimum t value for intersections.
 * @param tmax The maximum t value for intersections.
 * @param prd The payload to store the radiance information in.
 */
static __forceinline__ __device__ void traceRadiance(
  OptixTraversableHandle handle,
  float3                 ray_origin,
  float3                 ray_direction,
  float                  tmin,
  float                  tmax,
  RadiancePayloadRayData& prd
)
{
  unsigned int u0, u1, u2, u3, u4, u5, u6, u7, u8, u9, u10, u11, u12, u13, u14, u15, u16, u17, u18;

  u0 = __float_as_uint(prd.attenuation.x);
  u1 = __float_as_uint(prd.attenuation.y);
  u2 = __float_as_uint(prd.attenuation.z);
  u3 = prd.randomSeed;
  u4 = prd.depth;
  u18 = prd.doneReason;

  
  optixTraverse(
    RADIANCE_PAYLOAD_TYPE,
    handle,
    ray_origin,
    ray_direction,
    tmin,
    tmax,
    0.0f,                   // rayTime
    OptixVisibilityMask(1),
    OPTIX_RAY_FLAG_NONE,
    0,                      // SBT offset
    2,                      // SBT stride
    0,                      // missSBTIndex
    u0, u1, u2, u3, u4, u5, u6, u7, u8, u9, u10, u11, u12, u13, u14, u15, u16, u17, u18);
  
  // Note:
  // This demonstrates the usage of the OptiX shader execution reordering 
  // (SER) API.  In the case of this computationally simple shading code, 
  // there is no real performance benefit.  However, with more complex shaders
  // the potential performance gains offered by reordering are significant.
  optixReorder(
    // Application specific coherence hints could be passed in here
  );

  
  optixInvoke(
    RADIANCE_PAYLOAD_TYPE,
    u0, u1, u2, u3, u4, u5, u6, u7, u8, u9, u10, u11, u12, u13, u14, u15, u16, u17, u18
  );
  //printf("Did we get here?");

  prd.attenuation = make_float3(__uint_as_float(u0), __uint_as_float(u1), __uint_as_float(u2));
  prd.randomSeed = u3;
  prd.depth = u4;

  prd.emissionColor = make_float3(__uint_as_float(u5), __uint_as_float(u6), __uint_as_float(u7));
  prd.radiance = make_float3(__uint_as_float(u8), __uint_as_float(u9), __uint_as_float(u10));
  prd.origin = make_float3(__uint_as_float(u11), __uint_as_float(u12), __uint_as_float(u13));
  prd.direction = make_float3(__uint_as_float(u14), __uint_as_float(u15), __uint_as_float(u16));
  prd.done = u17;
  prd.doneReason = (DoneReason)u18;
}


/**
 * @brief Traces a shadow ray through the scene and returns if the ray is occluded.
 *
 * This function uses the OptiX API to trace a shadow ray through the scene and returns if the ray is occluded.
 * optixTraverse is used to trace the ray and optixHitObjectIsHit is used to check if the ray hit an object.
 *
 * @param handle The handle to the traversable object (scene) to trace the ray through.
 * @param ray_origin The origin of the ray.
 * @param ray_direction The direction of the ray.
 * @param tmin The minimum t value for intersections.
 * @param tmax The maximum t value for intersections.
 * @return true if the ray is occluded, false otherwise.
 */
static __forceinline__ __device__ bool traceOcclusion(
  OptixTraversableHandle handle,
  float3                 ray_origin,
  float3                 ray_direction,
  float                  tmin,
  float                  tmax
)
{
  // We are only casting probe rays so no shader invocation is needed
  optixTraverse(
    RADIANCE_PAYLOAD_TYPE,
    handle,
    ray_origin,
    ray_direction,
    tmin,
    tmax, 0.0f,                // rayTime
    OptixVisibilityMask(1),
    OPTIX_RAY_FLAG_TERMINATE_ON_FIRST_HIT | OPTIX_RAY_FLAG_DISABLE_ANYHIT,
    0,                         // SBT offset
    NUM_RAYTYPES,            // SBT stride
    0                          // missSBTIndex
  );
  if (optixHitObjectIsHit()) {
    // get the object that was hit 
    HitGroupData* rt_data = (HitGroupData*)optixGetSbtDataPointer();
    if (rt_data->bsdfType == BSDFType::BSDF_REFRACTION) {
      return false;
    }
    else {
      return true;
    }
  }

  return false;
}

/**
 * @brief Generates a ray for the current pixel and traces it through the scene.
 *
 * This function generates a ray for the current pixel and traces it through the scene.
 * The radiance information is accumulated and stored in the frame buffer.
 *
 * The function uses stratified sampling to generate rays for each pixel. Stratified sampling
 * is a method that divides the pixel into smaller sub-pixels and generates a sample within each sub-pixel.
 * This helps to reduce the variance and produce a more accurate image.
 *
 * The function also uses the Russian Roulette method for ray termination. This is a stochastic method
 * used to decide whether to continue or terminate a ray after each bounce. The decision is made based
 * on the intensity of the ray. If the ray's intensity is below a certain threshold, it has a certain
 * probability of being terminated. This helps to reduce the computational cost by not tracing rays
 * that contribute little to the final image.
 * 
 * This function was originally provided by the NVidia Optix toolkit, but has been modified to better suit the needs of this specific application.
 *
 * @param params The parameters for the path tracing, including the image width, height, camera parameters, 
 *               and the current frame index.
 */
extern "C" __global__ void __raygen__rg()
{

  const int    w = params.width;
  const int    h = params.height;
  const float3 eye = params.cameraEye;
  const float3 U = params.cameraU;
  const float3 V = params.cameraV;
  const float3 W = params.cameraW;
  const uint3  idx = optixGetLaunchIndex();
  const int    subframe_index = params.currentFrameIdx;
  const unsigned int maxDepth = params.maxDepth;
  

  unsigned int seed = tea<4>(idx.y * w + idx.x, subframe_index);

  float3 result = make_float3(0.0f);
  int i = params.samplesPerPixel;
  RadiancePayloadRayData prd;

  

  do
  {
    // The center of each pixel is at fraction (0.5,0.5)
    const float2 subpixel_jitter = make_float2(rnd(seed), rnd(seed));

    const float2 d = 2.0f * make_float2(
      (static_cast<float>(idx.x) + subpixel_jitter.x) / static_cast<float>(w),
      (static_cast<float>(idx.y) + subpixel_jitter.y) / static_cast<float>(h)
    ) - 1.0f;
    
    float3 ray_direction = normalize(d.x * U + d.y * V + W);
    float3 ray_origin = eye;


    // Initialize the payload for the first time
    prd.attenuation = make_float3(1.f); // The attenuation is initialized to 1
    prd.randomSeed = seed;
    prd.depth = 0;
    prd.doneReason = DoneReason::NOT_DONE;

    for (;; )
    {

      traceRadiance(
        params.handle,
        ray_origin,
        ray_direction,
        0.01f,  // tmin       
        1e16f,  // tmax
        prd
      );
      
      // at this point the PRD should be updated with the result of the trace
      result += prd.emissionColor;
      result += prd.radiance * prd.attenuation;

      const float p = dot(prd.attenuation, make_float3(0.30f, 0.59f, 0.11f)); // weight by perceived brightness to the human eye

      bool russianRoulette = rnd(prd.randomSeed) > p;

      const bool done = prd.done || russianRoulette || prd.depth >= maxDepth;
      if (done) {
        if(russianRoulette) prd.doneReason = DoneReason::RUSSIAN_ROULETTE;
        if(prd.depth >= maxDepth) prd.doneReason = DoneReason::MAX_DEPTH;
        break;
      }
      prd.attenuation = safeDivide(prd.attenuation, p);

      ray_origin = prd.origin;
      ray_direction = prd.direction;

      ++prd.depth;
    }
  } while (--i);

  const uint3    launch_index = optixGetLaunchIndex();
  const unsigned int image_index = launch_index.y * params.width + launch_index.x;
  float3         accum_color = result / static_cast<float>(params.samplesPerPixel);

  //if (
  //  pixelIsNull(accum_color) && 
  //  subframe_index > 500 && 
  //  prd.doneReason != DoneReason::MISS && 
  //  prd.doneReason != DoneReason::RUSSIAN_ROULETTE && 
  //  prd.doneReason != DoneReason::MAX_DEPTH
  //  )
  //{
  //  //char buffer[256];
  //  //const char* doneReason = doneReasonToString(prd.doneReason);
  //  //strncpy(buffer, doneReason, strlen(doneReason));
  //  printf("Current Depth: %d of %d\n", prd.depth, maxDepth);
  //  printf("Done Reason: %s\n", doneReasonToString(prd.doneReason));
  //  printf("result: %f, %f, %f\n", result.x, result.y, result.z);

  //}

  if (subframe_index > 0)
  {
    const float                 a = 1.0f / static_cast<float>(subframe_index + 1);
    const float3 accum_color_prev = make_float3(params.accumulationBuffer[image_index]);

    //the current frams is linear interpolated with the previous frames
    accum_color = lerp(accum_color_prev, accum_color, a);
  }
  params.accumulationBuffer[image_index] = make_float4(accum_color, 1.0f);
  
  //make_color is helper that clamps and gamma corrects the color into sRGB color space
  params.frameBuffer[image_index] = make_color(accum_color);

}


/**
 * @brief Handles the case when a ray does not hit any geometry in the scene.
 *
 * This function is part of the OptiX ray tracing pipeline and is invoked when a ray misses all the objects in the scene.
 * It sets the radiance of the ray to the background color, indicating that the ray hit the "sky" or background of the scene.
 * The function also sets the emission color to zero, as there is no light emission from the background.
 * The doneReason is set to MISS, indicating that the ray did not hit any geometry.
 * The done flag is set to true, indicating that the ray tracing for this ray is complete.
 *
 * This function was originally provided by the NVidia Optix toolkit, but has been modified to better suit the needs of this specific application.
 *
 * @note This function is a GPU kernel that is meant to be launched on the GPU.
 */

extern "C" __global__ void __miss__ms()
{

  optixSetPayloadTypes(RADIANCE_PAYLOAD_TYPE);

  MissData* rt_data = reinterpret_cast<MissData*>(optixGetSbtDataPointer());
  RadiancePayloadRayData prd = loadMissRadiancePRD();

  prd.radiance = make_float3(rt_data->backgroundColor);
  prd.emissionColor = make_float3(0.f);
  prd.doneReason = DoneReason::MISS;
  prd.done = true;

  storeMissRadiancePRD(prd);
}

extern "C" __global__ void __miss__volume__ms()
{
  // we expect most volume rays to miss geometry because they are ray marching through the volume
  // assume the end of the ray is inside the volume, this miss shader is being called at time step t
  // here is where we would accumulate the volume's emission and scattering properties

  // Sample to the volume at the current position and accumulate the volume's emission and scattering properties
  

  
  optixSetPayloadTypes(VOLUME_PAYLOAD_TYPE);
  VolumePayLoadRayData vrd = loadMissVolumePRD();
  

  printf("Volume miss invoked\n");


}

extern "C" __global__ void __closesthit__volume__ch() {
  // we are inside the volume and we hit something. 
  // what did we hit?
  // if we hit another surface in the volume, we shade the surface as usual and bounce the ray
  // if we hit the volume boundary, we need to mark the ray as done and return the volume's emission and scattering properties
  optixSetPayloadTypes(VOLUME_PAYLOAD_TYPE);
  VolumePayLoadRayData vrd = loadClosesthitVolumePRD();

 
  printf("Volume closest hit invoked\n");


 
}


/**
 * @brief Implements custom shading logic for rays intersecting scene geometry, meeting the assignment's requirements.
 *
 * Triggered within the NVIDIA OptiX ray tracing pipeline on ray-geometry intersections, this closest hit program handles
 * diffuse reflection, metallic surfaces using the GGX microfacet model, and refraction via Fresnel equations. It adjusts
 * reflection and transmission based on material properties, contributing significantly to the realistic rendering of materials.
 *
 * Designed for this assignment, the function supports importance sampling for diffuse reflections to accurately model light
 * distribution and incorporates direct lighting for enhanced realism. It processes specular interactions for metallic and
 * refractive materials, updates the ray's payload with color and radiance data, and manages emission from light sources.
 * The function also determines ray continuation or termination based on interactions with materials and scene geometry.
 *
 * This kernel is essential for the visual outcome of the rendering process, tailored to the specific requirements of the assignment.
 *
 */
extern "C" __global__ void __closesthit__diffuse__ch()
{

  optixSetPayloadTypes(RADIANCE_PAYLOAD_TYPE);

  HitGroupData* rt_data = (HitGroupData*)optixGetSbtDataPointer();


  const int       prim_idx = optixGetPrimitiveIndex();
  const float3    ray_dir = optixGetWorldRayDirection();

  const uint3     idx = rt_data->indices[prim_idx];
  const bool      useDirectLighting = params.useDirectLighting;
  const bool      useImportanceSampling = params.useImportanceSampling;
  const float     metalRoughOffset = params.metallicRoughness;
  const float     refractRoughOffset = params.refractiveRoughness;
  const float     metallic = rt_data->metallic; 
        float     roughness = rt_data->roughness;
  const float     IOR = rt_data->IOR;
  const BSDFType  bsdfType = rt_data->bsdfType;



  const float3 v0 = make_float3(rt_data->vertices[idx.x]);
  const float3 v1 = make_float3(rt_data->vertices[idx.y]);
  const float3 v2 = make_float3(rt_data->vertices[idx.z]);


  const float3 N_0 = normalize(cross(v1 - v0, v2 - v0));

  const float3 N = faceforward(N_0, -ray_dir, N_0);
  const float3 P = optixGetWorldRayOrigin() + optixGetRayTmax() * ray_dir;

  RadiancePayloadRayData prd = loadClosesthitRadiancePRD();

  if (prd.depth == 0)
    prd.emissionColor = rt_data->emissionColor;
  else
    prd.emissionColor = make_float3(0.0f);

  unsigned int seed = prd.randomSeed;

  switch (bsdfType)
  {
    case BSDFType::BSDF_DIFFUSE:
    {
      ShadeDiffuse(prd, rt_data, P, N);
      break;
    }
    case BSDFType::BSDF_METALLIC:
    {
      ShadeMetallic(prd, rt_data, P, N, ray_dir);
      break;
    }
    case BSDFType::BSDF_REFRACTION:
    {
      ShadeDielectric(prd, rt_data, P, N_0, ray_dir);
      break;

    }
    case BSDFType::BSDF_VOLUME: {
      //we hit the volume boundary, cast a volume ray at the hitpoint in the direction of the ray at for some distance
      
      //get the max extent from the volumes AABB 
      // divide by 100 to get the step size
      // loop trough the volume and accumulate the volume's emission and scattering properties
      // for(;;;) { volumePrd = copy(prd); traceVolume(volumePrd); if (volumePrd.done) break } prd = copy(volumePrd);

      //temporarily lets just send the ray through 
      prd.direction = ray_dir;
      prd.origin = P + prd.direction * 1e-4f;
    }
  }

  const float z1 = rnd(seed);
  const float z2 = rnd(seed);
  prd.randomSeed = seed;

  float weight = 0.01f;
  AreaLight light = params.areaLight;

  if (length(rt_data->emissionColor) > 0.0f && bsdfType != BSDFType::BSDF_VOLUME) {
    prd.radiance = rt_data->emissionColor;
    prd.done = true;
    prd.doneReason = DoneReason::LIGHT_HIT;
  }
  else {
    prd.radiance = make_float3(0.01f);
    prd.done = false;
  }


  if (useDirectLighting && bsdfType != BSDFType::BSDF_REFRACTION) // this direct lightin model does not work at all with refraction
  {
    weight = 0.0f;
    //perturb the light position
    const float3 light_pos = light.corner + light.v1 * z1 + light.v2 * z2;

    // Calculate properties of light sample (for area based pdf)
    const float  Ldist = length(light_pos - P);
    const float3 L = normalize(light_pos - P);
    const float  nDl = dot(N, L);
    const float  LnDl = -dot(light.normal, L);

        if (nDl > 0.0f && LnDl > 0.0f)
        {
          const bool occluded = traceOcclusion(params.handle,P,L,0.01f, Ldist - 0.01f);  

        if (!occluded)
        {
          const float A = length(cross(light.v1, light.v2));
          weight = nDl * LnDl * A / (M_PIf * Ldist * Ldist);
          prd.radiance += light.emission * weight;
        }
      }                               
  }
 


  storeClosesthitRadiancePRD(prd);
}
